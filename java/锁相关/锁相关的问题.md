# 锁相关的问题

## Q1: JAVA中，经常会听到说AQS是基于CAS实现的无锁同步器，为何说CAS是无锁的？

之所以说CAS（Compare-And-Swap，比较并交换）是“无锁”的，是因为它在实现同步时，不依赖于传统意义上会导致线程阻塞的操作系统锁。具体原因如下：

1. **原子操作**：CAS 是由硬件层面提供的一条原子指令。它尝试更新某个内存位置的值，但前提是该位置的当前值必须与预期值相匹配。整个比较和更新的过程是一个不可分割的原子操作。

2. **无线程挂起**：
    * 当一个线程尝试执行CAS操作时，它并不会像获取传统锁那样去“获取”一个锁。如果CAS操作失败（因为其他线程在此期间修改了该值），当前线程**不会被操作系统挂起**。
    * 相反，线程会得知操作失败，然后可以决定下一步做什么，通常是重试CAS操作（经常在一个循环中进行），或者执行其他逻辑。

3. **乐观机制**：CAS体现了一种乐观的并发控制策略。线程会乐观地尝试更新一个值。如果成功了，就继续执行。如果因为竞争导致失败，它可以选择重试。这种方式避免了获取和释放锁的开销，以及线程被置于休眠状态然后又被唤醒的潜在成本。

4. **与传统锁的对比**：
    * 传统锁（例如Java中早期版本的`synchronized`关键字，或操作系统的互斥锁）通常涉及线程获取独占访问权。如果锁不可用，尝试获取锁的线程通常会被操作系统调度器阻塞，并进入等待状态，直到锁被释放。CAS的核心机制避免了这种阻塞。

**在AQS（AbstractQueuedSynchronizer，抽象队列同步器）的上下文中：**

AQS广泛使用CAS操作来管理其内部状态，例如：

* 原子地改变同步状态（例如，尝试获取锁）。
* 管理等待线程的队列。

通过使用CAS，AQS能够以一种高效且可扩展的方式实现各种同步器（如`ReentrantLock`、`Semaphore`、`CountDownLatch`），尤其是在高并发竞争的场景下。虽然如果线程无法立即获取同步原语，它们可能仍会在AQS的队列中“等待”，但尝试获取/释放以及管理队列的基本机制通常依赖于这些非阻塞的CAS操作，这使得其底层机制在不使用重量级操作系统锁进行状态转换方面是“无锁”的。

## Q2: synchronize关键字使用的监视器锁相比于CAS，它有哪些不一样的地方？

`synchronized`关键字使用的监视器锁（Monitor Lock）与CAS（Compare-And-Swap）在实现同步的机制和特性上有显著的不同：

1. **阻塞与非阻塞**：
    * **`synchronized`**：是**阻塞式**的。当一个线程尝试获取一个已经被其他线程持有的`synchronized`锁时，该线程会被**挂起（阻塞）**，并进入等待队列，直到锁被释放。这涉及到操作系统的介入，进行线程状态的转换（运行态 -> 阻塞态 -> 就绪态）。
    * **CAS**：是**非阻塞式**的。线程执行CAS操作时，如果操作失败（例如，内存值与预期值不符），它**不会被挂起**。线程会立即知道操作失败，并可以决定是重试、放弃还是执行其他逻辑。这种方式通常被称为“自旋”或忙等待（如果选择重试）。

2. **实现层面**：
    * **`synchronized`**：是Java语言层面的关键字，其底层实现依赖于JVM和操作系统提供的互斥量（Mutex）。在早期版本中，`synchronized`的开销较大，因为它直接涉及到操作系统的锁。后续版本中，JVM对其进行了优化（如偏向锁、轻量级锁、自旋锁），以减少不必要的内核态切换，但在竞争激烈时仍会升级为重量级锁。
    * **CAS**：通常是**硬件层面**提供的原子指令（如CPU的`cmpxchg`指令）。Java通过`sun.misc.Unsafe`类或者`java.util.concurrent.atomic`包中的类来间接使用这些底层原子操作。

3. **乐观与悲观**：
    * **`synchronized`**：体现的是一种**悲观锁**的策略。它总是假设会有并发冲突，所以在访问共享资源之前必须先获取锁。
    * **CAS**：体现的是一种**乐观锁**的策略。它假设并发冲突不那么频繁，所以它会尝试直接更新数据，只有在更新时发现数据已经被其他线程修改（与预期值不符），才会认为操作失败。

4. **锁的获取与释放**：
    * **`synchronized`**：锁的获取和释放是隐式的。进入`synchronized`代码块或方法时自动获取锁，退出时自动释放锁。
    * **CAS**：不涉及传统意义上的“锁获取”和“锁释放”。它是一次性的原子操作，尝试比较并替换内存中的值。

5. **公平性**：
    * **`synchronized`**：是非公平锁。线程获取锁的顺序是不确定的，新来的线程可能比等待队列中的线程先获取到锁（取决于JVM的实现和锁的优化状态）。
    * **CAS**：本身不直接提供公平性保证。基于CAS实现的同步器（如`ReentrantLock`）可以提供公平或非公平的选择。

6. **开销**：
    * **`synchronized`**：在无竞争或低竞争情况下，经过JVM优化后（如偏向锁、轻量级锁），开销可以很小。但在高竞争情况下，升级为重量级锁后，线程阻塞和唤醒的开销较大。
    * **CAS**：如果CAS操作能够成功，开销很小。但如果竞争激烈，导致CAS操作反复失败并重试（自旋），会消耗CPU资源。如果自旋时间过长，性能可能还不如直接阻塞线程。

总结来说：

| 特性         | `synchronized` (监视器锁)                     | CAS (比较并交换)                               |
| :----------- | :-------------------------------------------- | :--------------------------------------------- |
| **阻塞行为** | 阻塞式 (线程挂起)                             | 非阻塞式 (失败后可重试或执行其他逻辑)          |
| **实现层面** | JVM/操作系统层面 (互斥量)                     | 硬件原子指令                                   |
| **并发策略** | 悲观锁                                        | 乐观锁                                         |
| **锁的控制** | 隐式获取和释放                                | 无传统锁概念，一次性原子操作                   |
| **公平性**   | 非公平 (默认)                                 | 本身无公平性，依赖上层实现                     |
| **主要开销** | 线程上下文切换 (高竞争时)                     | CPU自旋 (高竞争导致反复失败时)                 |

AQS（AbstractQueuedSynchronizer）巧妙地结合了CAS的无锁特性（用于状态管理和队列操作）和可能的线程阻塞（当CAS尝试失败且需要等待时，通过`LockSupport.park()`等机制挂起线程），从而构建出高效的同步组件。

## Q3: 相比于CAS, synchronize为何会阻塞线程？这么做的必要性是什么？

`synchronized`关键字在Java中用于实现互斥访问，它之所以会阻塞线程，是其设计机制的一部分，并且这种阻塞行为在某些情况下是必要的。

### `synchronized` 为何会阻塞线程？

1. **悲观锁机制**：`synchronized` 是一种悲观锁。它假设并发冲突总是会发生，因此在线程访问共享资源之前，必须先获得锁。
2. **操作系统层面的锁**：当一个线程尝试获取一个已经被其他线程持有的`synchronized`锁（监视器锁）时，如果获取失败，JVM通常会将该线程置于**阻塞状态**。这意味着线程的执行会暂停，并且它会被放入一个与该锁关联的等待队列中。这个过程涉及到操作系统的介入，将线程从运行态转换到阻塞态。
3. **等待锁释放**：被阻塞的线程会一直等待，直到持有锁的线程释放该锁。一旦锁被释放，JVM会从等待队列中唤醒一个或多个线程（具体取决于调度策略），这些被唤醒的线程会再次尝试获取锁。

### 阻塞线程的必要性是什么？

与CAS（Compare-And-Swap）这种非阻塞的、通常采用自旋等待的机制相比，`synchronized`的阻塞行为有其必要性和优势：

1. **CPU资源效率**：
    * **CAS的自旋**：如果CAS操作在高竞争情况下反复失败，线程会持续占用CPU进行自旋（循环尝试），这会浪费CPU周期，尤其是在锁被持有的时间较长时。
    * **`synchronized`的阻塞**：当线程被阻塞时，它会放弃CPU执行权，允许其他线程执行。这在锁竞争激烈或锁持有时间较长的场景下，可以更有效地利用CPU资源，避免了无意义的空转。

2. **避免活锁/饥饿问题（某种程度上）**：
    * 虽然`synchronized`默认是非公平的，但线程一旦进入等待队列，它最终有机会被唤醒并获取锁。
    * 相比之下，纯粹的自旋CAS在极端情况下可能导致某些线程长时间无法成功执行CAS操作，从而产生饥饿现象。

3. **简化编程模型**：
    * 对于开发者而言，`synchronized`提供了一种相对简单直观的同步方式。开发者不需要手动处理CAS的重试逻辑、ABA问题等复杂情况。线程的挂起和唤醒由JVM和操作系统管理。

4. **适应不同竞争场景**：
    * **低竞争**：现代JVM对`synchronized`进行了很多优化（如偏向锁、轻量级锁），在低竞争情况下，其开销可以很小，甚至避免了重量级锁的阻塞。
    * **高竞争**：当竞争加剧，锁升级为重量级锁时，阻塞机制能够防止CPU因过度自旋而过载。虽然上下文切换有开销，但在长时间等待的场景下，这通常比持续自旋更优。

**总结**：

`synchronized`通过阻塞线程来管理对共享资源的访问。这种阻塞机制的必要性在于：

* 在锁竞争激烈或锁持有时间较长时，**避免CPU资源的浪费**（相比于CAS的自旋）。
* 提供一种相对**简单**的并发控制模型。
* 通过JVM的锁升级策略，能够适应不同的并发竞争程度。

虽然CAS在低冲突和短临界区场景下可能表现更好，但`synchronized`的阻塞机制使其在更广泛的场景中，尤其是在高竞争和长临界区的情况下，成为一种合理且必要的同步手段。AQS（AbstractQueuedSynchronizer）等更高级的同步工具则试图结合两者的优点，例如在尝试获取锁时使用CAS，如果失败则可能将线程加入等待队列并阻塞。

## Q4: 什么情况下该使用CAS而不是`synchronized`？以及什么情况下该使用`synchronized`而不是CAS？

选择使用CAS（Compare-And-Swap）还是`synchronized`关键字取决于具体的并发场景、对性能的要求以及代码的复杂度。

### 什么情况下该使用CAS而不是`synchronized`？

1. **低到中度竞争的场景**：
    * 当线程冲突不频繁时，CAS的乐观尝试通常能够成功，避免了`synchronized`获取和释放锁的开销，以及线程阻塞和唤醒的上下文切换成本。
    * **示例**：原子类（如`AtomicInteger`、`AtomicLong`）的简单计数或状态更新，其中写操作相对较少。

2. **临界区非常短小**：
    * 如果受保护的代码执行速度非常快，那么CAS自旋等待的成本可能低于`synchronized`导致线程挂起的成本。
    * **示例**：更新一个简单的标志位。

3. **需要实现无锁数据结构或算法**：
    * CAS是构建无锁（Lock-Free）和等待无关（Wait-Free）算法的基础。如果你正在设计这类高度并发的数据结构（例如，无锁队列、无锁栈），CAS是核心工具。
    * **示例**：`java.util.concurrent`包中的许多类，如`ConcurrentLinkedQueue`，内部广泛使用CAS。

4. **对延迟敏感，希望避免线程阻塞**：
    * 在某些实时或对响应延迟要求极高的系统中，即使竞争可能导致CAS重试，也可能比线程阻塞和唤醒的延迟更可取。

5. **细粒度的并发控制**：
    * 当只需要对单个变量或非常小范围的数据进行原子更新时，使用`Atomic*`类（基于CAS）通常比用`synchronized`保护一个更大的代码块更高效。

### 什么情况下该使用`synchronized`而不是CAS？

1. **高竞争的场景**：
    * 当大量线程频繁竞争同一个资源时，CAS操作会反复失败并进行自旋，这会消耗大量CPU资源，性能可能急剧下降。
    * 在这种情况下，`synchronized`（特别是当它升级为重量级锁后）会将失败的线程阻塞，让出CPU，从而更有效地利用CPU资源。

2. **临界区较长或复杂**：
    * 如果受保护的代码块执行时间较长，或者包含复杂逻辑（例如，多个步骤、I/O操作），那么让线程在等待时阻塞（使用`synchronized`）通常比让它们自旋（使用CAS）更合适，因为长时间自旋是极大的浪费。

3. **代码简单性和可读性优先**：
    * `synchronized`是Java语言内置的关键字，使用起来更简单直观，易于理解和维护，不容易出错。
    * CAS编程（尤其是在循环中手动管理重试）相对复杂，需要更仔细地处理逻辑，例如ABA问题（尽管`AtomicStampedReference`可以解决）。

4. **需要锁的内置特性**：
    * `synchronized`天然支持可重入性。如果一个线程已经持有一个锁，它可以再次获取该锁而不会死锁。
    * 虽然基于CAS的`ReentrantLock`也支持可重入，但`synchronized`的使用更简洁。

5. **JVM的优化**：
    * 现代JVM对`synchronized`进行了大量优化（如偏向锁、轻量级锁、自适应自旋等）。在许多情况下，尤其是在竞争不激烈或锁持有时间不长时，`synchronized`的性能已经非常好，并且JVM可以根据竞争情况自动调整锁策略。

6. **当保护多个操作的原子性时**：
    * 如果需要确保一系列操作作为一个原子单元执行，`synchronized`块提供了一种清晰的方式来定义这个临界区。用CAS实现等效的复杂原子操作会困难得多。

**总结**：

* **CAS**：适用于**低竞争、短临界区、对性能要求极致**的场景，尤其是在实现底层并发组件时。
* **`synchronized`**：适用于**高竞争、长临界区、代码简单性优先**的场景，或者当JVM的内置锁优化已经足够满足需求时。

在实践中，`java.util.concurrent.atomic`包中的原子类是使用CAS的优秀示例。对于大多数常规的应用程序级同步需求，`synchronized`或`java.util.concurrent.locks.Lock`（如`ReentrantLock`，它内部也使用了CAS）通常是更安全和更易于管理的选择。

## Q5: synchronize实现的锁，历代版本JVM中，都对它进行了哪些优化?

`synchronized`实现的锁（也称为内置锁或监视器锁）在历代JVM版本中经历了多次优化，以提高其性能并减少不必要的开销。这些优化主要集中在减少锁的获取和释放成本，尤其是在低竞争或无竞争的情况下。

主要的优化手段包括：

1. **偏向锁 (Biased Locking) - JDK 1.6引入**
    * **目标场景**：在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取。
    * **工作原理**：当一个线程第一次获取锁时，JVM会将锁对象头中的标记（Mark Word）记录下获取该锁的线程ID，并进入偏向模式。之后，当该线程再次请求锁时，无需再进行任何同步操作（如CAS），直接就可以获取锁，从而极大地降低了获取锁的开销。
    * **锁撤销**：如果其他线程尝试获取这个偏向锁，偏向模式会被撤销（revoke）。撤销偏向锁需要等待全局安全点（Safe Point），然后根据锁对象目前是否被锁定，决定恢复到未锁定状态或升级为轻量级锁。
    * **优点**：在无竞争或单线程重复获取锁的场景下，性能提升显著。
    * **缺点**：如果程序中大多数锁都存在竞争，偏向锁的撤销会带来额外的开销。因此，在某些高竞争场景下，可以考虑禁用偏向锁 (`-XX:-UseBiasedLocking`)。

2. **轻量级锁 (Lightweight Locking) - JDK 1.6引入**
    * **目标场景**：当偏向锁被撤销后，或者在关闭偏向锁的情况下，如果存在少量线程交替获取锁，但锁的持有时间非常短。
    * **工作原理**：线程在获取锁时，JVM会尝试使用CAS操作将锁对象的Mark Word更新为指向持有锁线程的栈中锁记录（Lock Record）的指针。如果CAS成功，则线程获取锁。如果CAS失败，表示存在竞争，线程会尝试自旋（见下文）来等待锁释放，而不是立即在操作系统层面挂起线程。
    * **锁膨胀**：如果自旋一定次数后仍然无法获取锁，或者有其他线程同时在自旋等待同一个锁，轻量级锁就会膨胀（inflate）为重量级锁。
    * **优点**：避免了使用操作系统互斥量（Mutex）带来的性能开销，因为线程挂起和唤醒需要内核态和用户态的切换。
    * **缺点**：如果锁竞争激烈，自旋会消耗CPU，且最终仍可能膨胀为重量级锁，反而增加了开销。

3. **自旋锁 (Spin Locking) - JDK 1.4.2引入，JDK 1.6改进**
    * **目标场景**：当锁被其他线程持有的时间非常短时，当前线程可以通过执行一个忙循环（自旋）来等待锁，而不是立即被挂起。
    * **工作原理**：线程会执行一段空循环（或者做一些其他有用的事情），期望在短时间内锁会被释放。
    * **优点**：如果锁很快被释放，自旋可以避免线程上下文切换的开销。
    * **缺点**：如果锁被持有的时间较长，自旋会白白浪费CPU资源。

4. **适应性自旋锁 (Adaptive Spin Locking) - JDK 1.6引入**
    * **工作原理**：自旋的时间不再是固定的，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果JVM观察到在某个锁上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM就会认为这次自旋也很可能再次成功，进而它将允许自旋等待持续相对更长的时间。反之，如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。
    * **优点**：更智能地决定是否自旋以及自旋多久，提高了自旋的有效性。

5. **锁消除 (Lock Elision) - JDK 1.6引入 (需要JIT编译器支持)**
    * **工作原理**：通过逃逸分析（Escape Analysis），JIT编译器可以判断某些锁对象是否只在当前线程内可见（即不会逃逸到其他线程）。如果确定锁定的数据只被当前线程访问，那么这个锁就是不必要的，JIT编译器会在编译时将其消除。
    * **示例**：在一个方法内部创建了一个对象，并对这个对象加锁，但这个对象并没有被返回或赋值给外部引用。
    * **优点**：完全消除了不必要的锁操作，提升性能。

6. **锁粗化 (Lock Coarsening) - JDK 1.6引入 (需要JIT编译器支持)**
    * **工作原理**：如果JIT编译器检测到一系列连续的对同一个锁对象的加锁和解锁操作（通常在循环中），它会将这些操作合并成一个更大范围的锁。这样做是为了避免频繁地进行加锁和解锁操作带来的性能损耗。
    * **示例**：在循环内部对同一个对象反复加锁解锁。
    * **优点**：减少了加锁解锁的次数，降低了开销。

这些优化使得`synchronized`在很多情况下都能表现出良好的性能，使其不再是早期Java版本中那样“重量级”的代名词。JVM会根据运行时的具体情况动态地选择和应用这些锁优化策略。

## Q6: synchronized的内部实现有哪些细节，性能与AQS实现的锁相比有哪些差异？

TODO: 待补充内容...
